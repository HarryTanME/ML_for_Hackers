{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# File-Name:       priority_inbox.R           \n", "# Date:            2012-02-10                                \n", "# Author:          Drew Conway (drew.conway@nyu.edu)\n", "# Purpose:         Code for Chapter 4.  In this case study we will attempt to write a \"priority\n", "#                   inbox\" algorithm for ranking email by some measures of importance.  We will\n", "#                   define these measures based on a set of email features, which moves beyond\n", "#                   the simple work counts used in Chapter 3.\n", "# Data Used:       Email messages contained in ../../03-Classification/code/data/\n", "#                   source: http://spamassassin.apache.org/publiccorpus/\n", "# Packages Used:   tm, ggplot2, plyr\n", "\n", "# All source code is copyright (c) 2012, under the Simplified BSD License.  \n", "# For more information on FreeBSD see: http://www.opensource.org/licenses/bsd-license.php\n", "\n", "# All images and materials produced by this code are licensed under the Creative Commons \n", "# Attribution-Share Alike 3.0 United States License: http://creativecommons.org/licenses/by-sa/3.0/us/\n", "\n", "# All rights reserved.\n", "\n", "# NOTE: If you are running this in the R console you must use the 'setwd' command to set the \n", "# working directory for the console to whereever you have saved this file prior to running.\n", "# Otherwise you will see errors when loading data or saving figures!\n", "                       \n", "# Load libraries\n", "library('tm')\n", "library('ggplot2')\n", "library('plyr')\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Set the global paths\n", "data.path <- file.path(\"..\", \"03-Classification\", \"data\")\n", "easyham.path <- file.path(data.path, \"easy_ham\")\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# We define a set of function that will extract the data\n", "# for the feature set we have defined to rank email\n", "# impportance.  This includes the following: message\n", "# body, message source, message subject, and date the\n", "# message was sent.\n", "\n", "# Simply returns the full text of a given email message\n", "msg.full <- function(path)\n", "{\n", "  con <- file(path, open = \"rt\", encoding = \"latin1\")\n", "  msg <- readLines(con)\n", "  close(con)\n", "  return(msg)\n", "}\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Retuns the email address of the sender for a given\n", "# email message\n", "get.from <- function(msg.vec)\n", "{\n", "  from <- msg.vec[grepl(\"From: \", msg.vec)]\n", "  from <- strsplit(from, '[\":<> ]')[[1]]\n", "  from <- from[which(from  != \"\" & from != \" \")]\n", "  return(from[grepl(\"@\", from)][1])\n", "}\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Retuns the subject string for a given email message\n", "get.subject <- function(msg.vec)\n", "{\n", "  subj <- msg.vec[grepl(\"Subject: \", msg.vec)]\n", "  if(length(subj) > 0)\n", "  {\n", "    return(strsplit(subj, \"Subject: \")[[1]][2])\n", "  }\n", "  else\n", "  {\n", "    return(\"\")\n", "  }\n", "}\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Similar to the function from Chapter 3, this returns\n", "# only the message body for a given email.\n", "get.msg <- function(msg.vec)\n", "{\n", "  msg <- msg.vec[seq(which(msg.vec == \"\")[1] + 1, length(msg.vec), 1)]\n", "  return(paste(msg, collapse = \"\\n\"))\n", "}\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Retuns the date a given email message was received\n", "get.date <- function(msg.vec)\n", "{\n", "  date.grep <- grepl(\"^Date: \", msg.vec)\n", "  date.grep <- which(date.grep == TRUE)\n", "  date <- msg.vec[date.grep[1]]\n", "  date <- strsplit(date, \"\\\\+|\\\\-|: \")[[1]][2]\n", "  date <- gsub(\"^\\\\s+|\\\\s+$\", \"\", date)\n", "  return(strtrim(date, 25))\n", "}\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# This function ties all of the above helper functions together.\n", "# It returns a vector of data containing the feature set\n", "# used to categorize data as priority or normal HAM\n", "parse.email <- function(path)\n", "{\n", "  full.msg <- msg.full(path)\n", "  date <- get.date(full.msg)\n", "  from <- get.from(full.msg)\n", "  subj <- get.subject(full.msg)\n", "  msg <- get.msg(full.msg)\n", "  return(c(date, from, subj, msg, path))\n", "}\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# In this case we are not interested in classifiying SPAM or HAM, so we will take\n", "# it as given that is is being performed.  As such, we will use the EASY HAM email\n", "# to train and test our ranker.\n", "easyham.docs <- dir(easyham.path)\n", "easyham.docs <- easyham.docs[which(easyham.docs != \"cmds\")]\n", "easyham.parse <- lapply(easyham.docs,\n", "                        function(p) parse.email(file.path(easyham.path, p)))\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Convert raw data from list to data frame\n", "ehparse.matrix <- do.call(rbind, easyham.parse)\n", "allparse.df <- data.frame(ehparse.matrix, stringsAsFactors = FALSE)\n", "names(allparse.df) <- c(\"Date\", \"From.EMail\", \"Subject\", \"Message\", \"Path\")\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Convert date strings to POSIX for comparison. Because the emails data\n", "# contain slightly different date format pattners we have to account for\n", "# this by passining them as required partmeters of the function. \n", "date.converter <- function(dates, pattern1, pattern2)\n", "{\n", "  pattern1.convert <- strptime(dates, pattern1)\n", "  pattern2.convert <- strptime(dates, pattern2)\n", "  pattern1.convert[is.na(pattern1.convert)] <- pattern2.convert[is.na(pattern1.convert)]\n", "  return(pattern1.convert)\n", "}\n", "\n", "pattern1 <- \"%a, %d %b %Y %H:%M:%S\"\n", "pattern2 <- \"%d %b %Y %H:%M:%S\"\n", "\n", "allparse.df$Date <- date.converter(allparse.df$Date, pattern1, pattern2)\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Convert emails and subjects to lower-case\n", "allparse.df$Subject <- tolower(allparse.df$Subject)\n", "allparse.df$From.EMail <- tolower(allparse.df$From.EMail)\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Order the messages chronologically\n", "priority.df <- allparse.df[with(allparse.df, order(Date)), ]\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# We will use the first half of the priority.df to train our priority in-box algorithm.\n", "# Later, we will use the second half to test.\n", "priority.train <- priority.df[1:(round(nrow(priority.df) / 2)), ]\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# The first step is to create rank weightings for all of the features.\n", "# We begin with the simpliest: who the email is from.\n", "\n", "# Calculate the frequency of correspondence with all emailers in the training set\n", "from.weight <- melt(with(priority.train, table(From.EMail)), \n", "                    value.name=\"Freq\")\n", "\n", "from.weight <- from.weight[with(from.weight, order(Freq)), ]\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# We take a subset of the from.weight data frame to show our most frequent \n", "# correspondents.\n", "from.ex <- subset(from.weight, Freq > 6)\n", "\n", "from.scales <- ggplot(from.ex) +\n", "  geom_rect(aes(xmin = 1:nrow(from.ex) - 0.5,\n", "                xmax = 1:nrow(from.ex) + 0.5,\n", "                ymin = 0,\n", "                ymax = Freq,\n", "                fill = \"lightgrey\",\n", "                color = \"darkblue\")) +\n", "  scale_x_continuous(breaks = 1:nrow(from.ex), labels = from.ex$From.EMail) +\n", "  coord_flip() +\n", "  scale_fill_manual(values = c(\"lightgrey\" = \"lightgrey\"), guide = \"none\") +\n", "  scale_color_manual(values = c(\"darkblue\" = \"darkblue\"), guide = \"none\") +\n", "  ylab(\"Number of Emails Received (truncated at 6)\") +\n", "  xlab(\"Sender Address\") +\n", "  theme_bw() +\n", "  theme(axis.text.y = element_text(size = 5, hjust = 1))\n", "ggsave(plot = from.scales,\n", "       filename = file.path(\"images\", \"0011_from_scales.pdf\"),\n", "       height = 4.8,\n", "       width = 7)\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Log weight scheme, very simple but effective\n", "from.weight <- transform(from.weight,\n", "                         Weight = log(Freq + 1),\n", "                         log10Weight = log10(Freq + 1))\n", "\n", "from.rescaled <- ggplot(from.weight, aes(x = 1:nrow(from.weight))) +\n", "  geom_line(aes(y = Weight, linetype = \"ln\")) +\n", "  geom_line(aes(y = log10Weight, linetype = \"log10\")) +\n", "  geom_line(aes(y = Freq, linetype = \"Absolute\")) +\n", "  scale_linetype_manual(values = c(\"ln\" = 1,\n", "                                   \"log10\" = 2,\n", "                                   \"Absolute\" = 3),\n", "                        name = \"Scaling\") +\n", "  xlab(\"\") +\n", "  ylab(\"Number of emails Receieved\") +\n", "  theme_bw() +\n", "  theme(axis.text.y = element_blank(), axis.text.x = element_blank())\n", "ggsave(plot = from.rescaled,\n", "       filename = file.path(\"images\", \"0012_from_rescaled.pdf\"),\n", "       height = 4.8,\n", "       width = 7)\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# To calculate the rank priority of an email we should calculate some probability that \n", "# the user will respond to it.  In our case, we only have one-way communication data.\n", "# In this case, we can calculate a weighting based on words in threads that have a lot\n", "# of activity.\n", "\n", "# This function is used to find threads within the data set.  The obvious approach\n", "# here is to use the 're:' cue from the subject line to identify message threads.\n", "find.threads <- function(email.df)\n", "{\n", "  response.threads <- strsplit(email.df$Subject, \"re: \")\n", "  is.thread <- sapply(response.threads,\n", "                      function(subj) ifelse(subj[1] == \"\", TRUE, FALSE))\n", "  threads <- response.threads[is.thread]\n", "  senders <- email.df$From.EMail[is.thread]\n", "  threads <- sapply(threads,\n", "                    function(t) paste(t[2:length(t)], collapse = \"re: \"))\n", "  return(cbind(senders,threads))\n", "}\n", "\n", "threads.matrix <- find.threads(priority.train)\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Using the matrix of threads generated by the find.threads function this function\n", "# creates a data from of the sender's email, the frequency of emails from that\n", "# sender, and a log-weight for that sender based on the freqeuncy of corresponence.\n", "email.thread <- function(threads.matrix)\n", "{\n", "  senders <- threads.matrix[, 1]\n", "  senders.freq <- table(senders)\n", "  senders.matrix <- cbind(names(senders.freq),\n", "                          senders.freq,\n", "                          log(senders.freq + 1))\n", "  senders.df <- data.frame(senders.matrix, stringsAsFactors=FALSE)\n", "  row.names(senders.df) <- 1:nrow(senders.df)\n", "  names(senders.df) <- c(\"From.EMail\", \"Freq\", \"Weight\")\n", "  senders.df$Freq <- as.numeric(senders.df$Freq)\n", "  senders.df$Weight <- as.numeric(senders.df$Weight)\n", "  return(senders.df)\n", "}\n", "\n", "senders.df <- email.thread(threads.matrix)\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# As an additional weight, we can enhance our notion of a thread's importance\n", "# by measuring the time between responses for a given email.  This function\n", "# takes a given thread and the email.df data frame to generate a weighting \n", "# based on this activity level.  This function returns a vector of thread\n", "# activity, the time span of a thread, and its log-weight.\n", "thread.counts <- function(thread, email.df)\n", "{\n", "  # Need to check that we are not looking at the original message in a thread, \n", "  # so we check the subjects against the 're:' cue.\n", "  thread.times <- email.df$Date[which(email.df$Subject == thread |\n", "                                      email.df$Subject == paste(\"re:\", thread))]\n", "  freq <- length(thread.times)\n", "  min.time <- min(thread.times)\n", "  max.time <- max(thread.times)\n", "  time.span <- as.numeric(difftime(max.time, min.time, units = \"secs\"))\n", "  if(freq < 2)\n", "  {\n", "    return(c(NA, NA, NA))\n", "  }\n", "  else\n", "  {\n", "    trans.weight <- freq / time.span\n", "    log.trans.weight <- 10 + log(trans.weight, base = 10)\n", "    return(c(freq, time.span, log.trans.weight))\n", "  }\n", "}\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# This function uses the threads.counts function to generate a weights\n", "# for all email threads.\n", "get.threads <- function(threads.matrix, email.df)\n", "{\n", "  threads <- unique(threads.matrix[, 2])\n", "  thread.counts <- lapply(threads,\n", "                          function(t) thread.counts(t, email.df))\n", "  thread.matrix <- do.call(rbind, thread.counts)\n", "  return(cbind(threads, thread.matrix))\n", "}\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Now, we put all of these function to work to generate a training set\n", "# based on our thread features.\n", "thread.weights <- get.threads(threads.matrix, priority.train)\n", "thread.weights <- data.frame(thread.weights, stringsAsFactors = FALSE)\n", "names(thread.weights) <- c(\"Thread\", \"Freq\", \"Response\", \"Weight\")\n", "thread.weights$Freq <- as.numeric(thread.weights$Freq)\n", "thread.weights$Response <- as.numeric(thread.weights$Response)\n", "thread.weights$Weight <- as.numeric(thread.weights$Weight)\n", "thread.weights <- subset(thread.weights, is.na(thread.weights$Freq) == FALSE)\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Similar to what we did in Chapter 3, we create a simple function to return a \n", "# vector of word counts.  This time, however, we keep the TDM as a free\n", "# parameter of the function.\n", "term.counts <- function(term.vec, control)\n", "{\n", "  vec.corpus <- Corpus(VectorSource(term.vec))\n", "  vec.tdm <- TermDocumentMatrix(vec.corpus, control = control)\n", "  return(rowSums(as.matrix(vec.tdm)))\n", "}\n", "\n", "thread.terms <- term.counts(thread.weights$Thread,\n", "                            control = list(stopwords = TRUE))\n", "thread.terms <- names(thread.terms)\n", "\n", "term.weights <- sapply(thread.terms,\n", "                       function(t) mean(thread.weights$Weight[grepl(t, thread.weights$Thread, fixed = TRUE)]))\n", "term.weights <- data.frame(list(Term = names(term.weights),\n", "                                Weight = term.weights),\n", "                           stringsAsFactors = FALSE,\n", "                           row.names = 1:length(term.weights))\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Finally, create weighting based on frequency of terms in email. \n", "# Will be similar to SPAM detection, but in this case weighting\n", "# high words that are particularly HAMMMY.\n", "\n", "msg.terms <- term.counts(priority.train$Message,\n", "                         control = list(stopwords = TRUE,\n", "                         removePunctuation = TRUE,\n", "                         removeNumbers = TRUE))\n", "msg.weights <- data.frame(list(Term = names(msg.terms),\n", "                               Weight = log(msg.terms, base = 10)),\n", "                          stringsAsFactors = FALSE,\n", "                          row.names = 1:length(msg.terms))\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Remove words that have a zero weight\n", "msg.weights <- subset(msg.weights, Weight > 0)\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# This function uses our pre-calculated weight data frames to look up\n", "# the appropriate weightt for a given search.term.  We use the 'term'\n", "# parameter to dertermine if we are looking up a word in the weight.df\n", "# for it message body weighting, or for its subject line weighting.\n", "get.weights <- function(search.term, weight.df, term = TRUE)\n", "{\n", "  if(length(search.term) > 0)\n", "  {\n", "    if(term)\n", "    {\n", "      term.match <- match(names(search.term), weight.df$Term)\n", "    }\n", "    else\n", "    {\n", "      term.match <- match(search.term, weight.df$Thread)\n", "    }\n", "    match.weights <- weight.df$Weight[which(!is.na(term.match))]\n", "    if(length(match.weights) < 1)\n", "    {\n", "      return(1)\n", "    }\n", "    else\n", "    {\n", "      return(mean(match.weights))\n", "    }\n", "  }\n", "  else\n", "  {\n", "    return(1)\n", "  }\n", "}\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Our final step is to write a function that will assign a weight to each message based\n", "# on all of our, we create a function that will assign a weight to each message based on\n", "# the mean weighting across our entire feature set.\n", "rank.message <- function(path)\n", "{\n", "  msg <- parse.email(path)\n", "  # Weighting based on message author\n", "  \n", "  # First is just on the total frequency\n", "  from <- ifelse(length(which(from.weight$From.EMail == msg[2])) > 0,\n", "                 from.weight$Weight[which(from.weight$From.EMail == msg[2])],\n", "                 1)\n", "  \n", "  # Second is based on senders in threads, and threads themselves\n", "  thread.from <- ifelse(length(which(senders.df$From.EMail == msg[2])) > 0,\n", "                        senders.df$Weight[which(senders.df$From.EMail == msg[2])],\n", "                        1)\n", "  \n", "  subj <- strsplit(tolower(msg[3]), \"re: \")\n", "  is.thread <- ifelse(subj[[1]][1] == \"\", TRUE, FALSE)\n", "  if(is.thread)\n", "  {\n", "    activity <- get.weights(subj[[1]][2], thread.weights, term = FALSE)\n", "  }\n", "  else\n", "  {\n", "    activity <- 1\n", "  }\n", "  \n", "  # Next, weight based on terms    \n", "  \n", "  # Weight based on terms in threads\n", "  thread.terms <- term.counts(msg[3], control = list(stopwords = TRUE))\n", "  thread.terms.weights <- get.weights(thread.terms, term.weights)\n", "  \n", "  # Weight based terms in all messages\n", "  msg.terms <- term.counts(msg[4],\n", "                           control = list(stopwords = TRUE,\n", "                           removePunctuation = TRUE,\n", "                           removeNumbers = TRUE))\n", "  msg.weights <- get.weights(msg.terms, msg.weights)\n", "  \n", "  # Calculate rank by interacting all weights\n", "  rank <- prod(from,\n", "               thread.from,\n", "               activity, \n", "               thread.terms.weights,\n", "               msg.weights)\n", "  \n", "  return(c(msg[1], msg[2], msg[3], rank))\n", "}\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Find splits again\n", "train.paths <- priority.df$Path[1:(round(nrow(priority.df) / 2))]\n", "test.paths <- priority.df$Path[((round(nrow(priority.df) / 2)) + 1):nrow(priority.df)]\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Now, create a full-featured training set.\n", "train.ranks <- suppressWarnings(lapply(train.paths, rank.message))\n", "train.ranks.matrix <- do.call(rbind, train.ranks)\n", "train.ranks.matrix <- cbind(train.paths, train.ranks.matrix, \"TRAINING\")\n", "train.ranks.df <- data.frame(train.ranks.matrix, stringsAsFactors = FALSE)\n", "names(train.ranks.df) <- c(\"Message\", \"Date\", \"From\", \"Subj\", \"Rank\", \"Type\")\n", "train.ranks.df$Rank <- as.numeric(train.ranks.df$Rank)\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Set the priority threshold to the median of all ranks weights\n", "priority.threshold <- median(train.ranks.df$Rank)\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Visualize the results to locate threshold\n", "threshold.plot <- ggplot(train.ranks.df, aes(x = Rank)) +\n", "  stat_density(aes(fill=\"darkred\")) +\n", "  geom_vline(xintercept = priority.threshold, linetype = 2) +\n", "  scale_fill_manual(values = c(\"darkred\" = \"darkred\"), guide = \"none\") +\n", "  theme_bw()\n", "ggsave(plot = threshold.plot,\n", "       filename = file.path(\"images\", \"01_threshold_plot.pdf\"),\n", "       height = 4.7,\n", "       width = 7)\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Classify as priority, or not\n", "train.ranks.df$Priority <- ifelse(train.ranks.df$Rank >= priority.threshold, 1, 0)\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Now, test our ranker by performing the exact same procedure on the test data\n", "test.ranks <- suppressWarnings(lapply(test.paths,rank.message))\n", "test.ranks.matrix <- do.call(rbind, test.ranks)\n", "test.ranks.matrix <- cbind(test.paths, test.ranks.matrix, \"TESTING\")\n", "test.ranks.df <- data.frame(test.ranks.matrix, stringsAsFactors = FALSE)\n", "names(test.ranks.df) <- c(\"Message\",\"Date\",\"From\",\"Subj\",\"Rank\",\"Type\")\n", "test.ranks.df$Rank <- as.numeric(test.ranks.df$Rank)\n", "test.ranks.df$Priority <- ifelse(test.ranks.df$Rank >= priority.threshold, 1, 0)\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"autoscroll": false, "collapsed": true}, "outputs": [], "source": ["# Finally, we combine the data sets.\n", "final.df <- rbind(train.ranks.df, test.ranks.df)\n", "final.df$Date <- date.converter(final.df$Date, pattern1, pattern2)\n", "final.df <- final.df[rev(with(final.df, order(Date))), ]\n", "\n"]}], "metadata": {"kernelspec": {"display_name": "R", "language": "R", "name": "ir"}, "language_info": {"codemirror_mode": "r", "file_extension": ".r", "mimetype": "text/x-r-source", "name": "R", "pygments_lexer": "r"}}, "nbformat": 4, "nbformat_minor": 0}